name: Deploy MeCabal Backend

on:
  push:
    branches: [ main, develop ]
    paths: [ 'backend/**' ]
  pull_request:
    branches: [ main ]
    paths: [ 'backend/**' ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production

permissions:
  contents: read
  packages: write
  id-token: write

env:
  NODE_VERSION: '22'
  DOCKER_REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository_owner }}/mecabal-backend

jobs:
  test:
    name: Test Backend
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./backend
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: backend/package-lock.json
    
    - name: Install dependencies
      run: npm ci

    # - name: Run linting
    #   run: npm run lint

    - name: Run tests
      run: npm run test
      env:
        NODE_ENV: test
      continue-on-error: true

    - name: Run e2e tests
      run: npm run test:e2e
      env:
        NODE_ENV: test
      continue-on-error: true

  build-and-push:
    name: Build and Push Docker Images
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    permissions:
      contents: read
      packages: write

    defaults:
      run:
        working-directory: ./backend

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: backend/package-lock.json

    - name: Install dependencies
      run: npm ci

    - name: Build applications
      run: npm run build

    - name: Log in to GitHub Container Registry
      uses: docker/login-action@v3
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata for Docker
      id: meta
      run: |
        echo "sha_short=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT
        echo "timestamp=$(date +%s)" >> $GITHUB_OUTPUT

    - name: Build and push all service images
      run: |
        # Force lowercase for Docker registry (required by Docker)
        REGISTRY_OWNER=$(echo "${{ github.repository_owner }}" | tr '[:upper:]' '[:lower:]')
        REGISTRY=ghcr.io/${REGISTRY_OWNER}/mecabal
        SHA_TAG=${{ steps.meta.outputs.sha_short }}

        # Build and push all 10 services
        for SERVICE in api-gateway auth-service user-service social-service messaging-service marketplace-service events-service notification-service location-service business-service; do
          echo "Building and pushing $SERVICE..."
          docker build -t $REGISTRY-$SERVICE:latest -t $REGISTRY-$SERVICE:$SHA_TAG -f Dockerfile --target runner .
          docker push $REGISTRY-$SERVICE:latest
          docker push $REGISTRY-$SERVICE:$SHA_TAG
        done

  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: build-and-push
    if: github.ref == 'refs/heads/develop' || (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'staging')
    environment: staging

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Deploy to staging server
      uses: appleboy/ssh-action@v1.0.3
      env:
        GH_PAT: ${{ secrets.GH_PAT }}
        GH_ACTOR: ${{ github.actor }}
      with:
        host: ${{ secrets.STAGING_HOST }}
        username: ${{ secrets.STAGING_USERNAME }}
        key: ${{ secrets.STAGING_SSH_KEY }}
        port: ${{ secrets.STAGING_PORT || 22 }}
        envs: GH_PAT,GH_ACTOR
        script: |
          # Navigate to project directory
          cd ${{ secrets.STAGING_PROJECT_PATH }}

          # Create backup tag for rollback
          docker-compose -f docker-compose.production.yml exec -T postgres pg_dump -U $DATABASE_USERNAME $DATABASE_NAME > backup_staging_$(date +%Y%m%d_%H%M%S).sql || echo "Backup skipped (first deployment)"

          # Pull latest code
          git pull origin develop

          # Update environment variables from secrets
          echo "${{ secrets.STAGING_ENV }}" | base64 -d > .env

          # Ensure Docker config directory exists
          mkdir -p ~/.docker

          # Login to GitHub Container Registry and persist credentials
          # Using GH_PAT (Personal Access Token) for better persistence
          # This stores credentials in ~/.docker/config.json for future use
          echo "$GH_PAT" | docker login ghcr.io -u "$GH_ACTOR" --password-stdin
          
          # Verify login was successful
          if [ $? -eq 0 ]; then
            echo "✓ Successfully authenticated with GitHub Container Registry"
            echo "✓ Credentials saved to ~/.docker/config.json (persistent)"
          else
            echo "✗ Failed to authenticate with GitHub Container Registry"
            exit 1
          fi

          # Pull latest Docker images
          docker-compose -f docker-compose.production.yml pull

          # Stop existing containers gracefully
          docker-compose -f docker-compose.production.yml down --timeout 30

          # Run database migrations
          docker-compose -f docker-compose.production.yml run --rm api-gateway npm run migration:run || echo "Migration skipped or failed"

          # Start new containers
          docker-compose -f docker-compose.production.yml up -d

          # Wait for services to be healthy
          echo "Waiting for services to start..."
          sleep 45

          # Run comprehensive health checks for all 10 services
          echo "Running health checks..."
          curl -f http://localhost:3000/health || exit 1
          curl -f http://localhost:3001/health || exit 1
          curl -f http://localhost:3002/health || exit 1
          curl -f http://localhost:3003/health || exit 1
          curl -f http://localhost:3004/health || exit 1
          curl -f http://localhost:3005/health || exit 1
          curl -f http://localhost:3006/health || exit 1
          curl -f http://localhost:3007/health || exit 1
          curl -f http://localhost:3008/health || exit 1
          curl -f http://localhost:3009/health || exit 1

          # Clean up old images
          docker image prune -f

          echo "Staging deployment completed successfully!"

  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: build-and-push
    if: github.ref == 'refs/heads/main' || (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'production')
    environment: production

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Deploy to production server
      id: deploy
      uses: appleboy/ssh-action@v1.0.3
      env:
        GH_PAT: ${{ secrets.GH_PAT }}
        GH_ACTOR: ${{ github.actor }}
      with:
        host: ${{ secrets.PRODUCTION_HOST }}
        username: ${{ secrets.PRODUCTION_USERNAME }}
        key: ${{ secrets.PRODUCTION_SSH_KEY }}
        port: ${{ secrets.PRODUCTION_PORT || 22 }}
        envs: GH_PAT,GH_ACTOR
        script: |
          # Navigate to project directory
          cd ${{ secrets.PRODUCTION_PROJECT_PATH }}

          # Store current commit for potential rollback
          PREVIOUS_COMMIT=$(git rev-parse HEAD)
          echo "Previous commit: $PREVIOUS_COMMIT"

          # Create timestamped backup of current deployment
          BACKUP_FILE="backup_production_$(date +%Y%m%d_%H%M%S).sql"
          echo "Creating database backup: $BACKUP_FILE"

          # Load environment variables for backup
          if [ -f .env.production ]; then
            export $(cat .env.production | grep -E "^DATABASE_[A-Z_]+=" | xargs)
          fi

          # Create backup (skip if database doesn't exist yet)
          docker-compose -f docker-compose.production.yml exec -T postgres pg_dump -U ${DATABASE_USERNAME:-mecabal} ${DATABASE_NAME:-mecabal_prod} > $BACKUP_FILE 2>/dev/null || echo "Skipping backup (first deployment or database not ready)"

          # Keep only last 7 backups
          ls -t backup_production_*.sql | tail -n +8 | xargs -r rm

          # Pull latest code
          git pull origin main
          CURRENT_COMMIT=$(git rev-parse HEAD)
          echo "New commit: $CURRENT_COMMIT"

          # Update environment variables from secrets
          echo "${{ secrets.PRODUCTION_ENV }}" | base64 -d > .env.production

          # Load only database environment variables for pg_dump (safely)
          export $(cat .env.production | grep -E "^DATABASE_[A-Z_]+=" | xargs)
          echo "✓ Environment variables loaded"

          # Ensure Docker config directory exists
          mkdir -p ~/.docker

          # Login to GitHub Container Registry and persist credentials
          # Using GH_PAT (Personal Access Token) for better persistence
          # This stores credentials in ~/.docker/config.json for future use (including manual docker-compose commands)
          echo "$GH_PAT" | docker login ghcr.io -u "$GH_ACTOR" --password-stdin
          
          # Verify login was successful
          if [ $? -eq 0 ]; then
            echo "✓ Successfully authenticated with GitHub Container Registry"
            echo "✓ Credentials saved to ~/.docker/config.json (persistent)"
            echo "✓ Manual 'docker-compose up' commands will now work without re-authentication"
          else
            echo "✗ Failed to authenticate with GitHub Container Registry"
            exit 1
          fi

          # Stop existing containers gracefully
          echo "Stopping services gracefully..."
          docker-compose -f docker-compose.production.yml down --timeout 30

          # IMPORTANT: DO NOT remove PostgreSQL volume in production
          # This preserves all data between deployments
          # Only manually remove volume if absolutely necessary for recovery
          echo "Preserving PostgreSQL data volume..."

          # Pull pre-built images from GitHub Container Registry (5-10x faster than building!)
          echo "Pulling latest Docker images from registry..."
          docker-compose -f docker-compose.production.yml pull

          # Start infrastructure services
          echo "Starting infrastructure services..."
          docker-compose -f docker-compose.production.yml up -d postgres redis rabbitmq minio

          # Wait for infrastructure to be healthy
          echo "Waiting for database to be ready..."
          for i in {1..30}; do
            if docker-compose -f docker-compose.production.yml exec -T postgres pg_isready -U ${DATABASE_USERNAME:-mecabal} > /dev/null 2>&1; then
              echo "Database is ready!"
              break
            fi
            echo "Waiting for database... ($i/30)"
            sleep 2
          done

          # Check if database has tables (detect first deployment)
          TABLE_COUNT=$(docker-compose -f docker-compose.production.yml exec -T postgres psql -U ${DATABASE_USERNAME:-mecabal} -d ${DATABASE_NAME:-mecabal_prod} -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public';" 2>/dev/null | xargs || echo "0")

          if [ "$TABLE_COUNT" = "0" ]; then
            echo "First deployment detected - setting up database schema..."
            # Start ONLY user-service with synchronize enabled to create schema
            DATABASE_SYNCHRONIZE=true docker-compose -f docker-compose.production.yml up -d user-service
            sleep 20
            docker-compose -f docker-compose.production.yml stop user-service
          else
            echo "Existing database detected - running migrations..."
            docker-compose -f docker-compose.production.yml run --rm -e DATABASE_SYNCHRONIZE=false auth-service npm run migration:run || {
              echo "Migration failed! Check logs for details"
              # Don't exit on migration failure - allow deployment to continue
            }
          fi

          # Start all services with newly built images (without synchronize to avoid conflicts)
          echo "Starting all services..."
          docker-compose -f docker-compose.production.yml up -d --remove-orphans

          # Wait for services to start
          echo "Waiting for services to start..."
          sleep 30

          # Check container status
          echo "Checking container status..."
          docker-compose -f docker-compose.production.yml ps

          # Show logs for any unhealthy containers
          echo "Checking for unhealthy containers..."
          UNHEALTHY=$(docker ps --filter health=unhealthy --format "{{.Names}}")
          if [ ! -z "$UNHEALTHY" ]; then
            echo "WARNING: Unhealthy containers detected: $UNHEALTHY"
            for container in $UNHEALTHY; do
              echo "=== Logs for $container ==="
              docker logs --tail 50 $container
            done
          fi

          # Additional wait for health checks
          echo "Waiting for health checks to complete..."
          sleep 30

          # Run comprehensive health checks for all 10 services
          echo "Running health checks..."
          HEALTH_CHECK_FAILED=0

          # Try health checks with retries
          for ATTEMPT in {1..3}; do
            echo "Health check attempt $ATTEMPT/3..."
            FAILED_SERVICES=""

            for PORT in 3000 3001 3002 3003 3004 3005 3006 3007 3008 3009; do
              if curl -f -s http://localhost:$PORT/health > /dev/null 2>&1; then
                echo "✓ Service on port $PORT is healthy"
              else
                echo "✗ Service on port $PORT not responding"
                FAILED_SERVICES="$FAILED_SERVICES $PORT"
              fi
            done

            if [ -z "$FAILED_SERVICES" ]; then
              echo "All services are healthy!"
              HEALTH_CHECK_FAILED=0
              break
            else
              echo "Services not ready on ports:$FAILED_SERVICES"
              if [ $ATTEMPT -lt 3 ]; then
                echo "Waiting 20 seconds before retry..."
                sleep 20
              else
                HEALTH_CHECK_FAILED=1
              fi
            fi
          done

          if [ $HEALTH_CHECK_FAILED -eq 1 ]; then
            echo "WARNING: Some services are not responding to health checks"
            echo "Checking container logs..."
            docker-compose -f docker-compose.production.yml logs --tail=100

            echo "Deployment completed with warnings. Please check logs manually."
            echo "To check service status: docker-compose -f docker-compose.production.yml ps"
            echo "To view logs: docker-compose -f docker-compose.production.yml logs -f [service-name]"
          fi

          # Clean up old images to save space
          docker image prune -f

          echo "Production deployment completed successfully!"
          echo "Deployed commit: $CURRENT_COMMIT"
          echo "Backup available at: $BACKUP_FILE"

  notify:
    name: Notify Deployment Status
    runs-on: ubuntu-latest
    needs: [deploy-staging, deploy-production]
    if: always()
    
    steps:
    - name: Notify Slack
      if: env.SLACK_WEBHOOK_URL
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        text: |
          MeCabal Backend Deployment ${{ job.status }}
          Branch: ${{ github.ref }}
          Commit: ${{ github.sha }}
          Author: ${{ github.actor }}
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
